---
title: "Data_Manipulation_R"
author: "Ravi Mummigatti"
date: "9/27/2021"
output:
  html_document:
    df_print: paged
    theme: cerulean
    highlight: haddock
    toc: yes
    toc_float: yes
    number_sections: yes
---

```{r setup , message=FALSE , include=FALSE}
knitr::opts_chunk$set(echo = TRUE , cache.lazy = FALSE , warning = FALSE , message = FALSE , fig.width = 10 , fig.height = 5)
```

# Introduction

Data manipulation involves modifying data to make it easier to read and to be more organized. We manipulate data for analysis and visualization. It is also used with the term 'data exploration' which involves organizing data using available sets of variables.\
At times, the data collection process done by machines involves a lot of errors and inaccuracies in reading. Data manipulation is also used to remove these inaccuracies and make data more accurate and precise.

We will apply various functions from the **"Tidyverse"** package to manipulate / transform our data to derive meaningful insights

**Load tidyverse**

We will use the dplyr package from the tidyverse meta package to accomplish various tasks

```{r , message=FALSE , warning=FALSE}
library(tidyverse)
```

## Pipe (%\>%) Operator

Modern filtering is done with \*\*dplyr\*\* package. It has a consistent and clean way of defining filters.It makes use of piping, which is why this technique is shown here.To understand why it is useful, you need to understand what the drawbacks without piping are. Assume you have a vector of numbers. Can you understand what the second line of this expression does?

```{r}
x <- c(0.109, 0.359, 0.63, 0.996, 0.515, 0.142, 0.017, 0.829, 0.907)
round(exp(diff(log(x))), 1)
```

You have to read this from "Inside to Outside"

Step 1 : Take the log of (x)

Step 2 : Take the difference

Step 3 : Take the Exponent

Step 4 : Round the result to "1" decimal

Each function is nested within another function. It is hard to read and understand

The same task can be performed by "piping" using the "%\>%" operator. The %\>% "PIPE" takes the variable on the left side of the piping operator as first parameter of the function. There is no nesting of functions any more.

```{r}
x <- c(0.109, 0.359, 0.63, 0.996, 0.515, 0.142, 0.017, 0.829, 0.907)

x %>%  # take the vector (x)
  log() %>% # take the logarithm
  diff() %>% # take the difference
  exp() %>%  # take the exponent
  round(1) # finally round to 1 decimal
```

# Transforming Data

In this section we will learn to use four basic dplyr verbs to explore and transform a dataset.

**Dataset Reference**

We will reference the United States Census data for the year 2015.A state is one of 50 regions within the United States, such as New York, California, or Texas. A county is a sub-region of one of those states, e.g. Los-Angeles is a county in the state of California.This dataset includes information about people living in each county, such as the population, the unemployment rate, their income, and their racial and gender breakdown, so there are a lot of questions we can ask of our data.There are 40 variables in this data

**Load Data**

We will read the .rds file from the specified url and store it in a dataframe mydata

```{r , message=FALSE , warning=FALSE}
# mydata <- readRDS(url("https://assets.datacamp.com/production/repositories/4984/datasets/a924bf7063f02a5445e1f49cc1c75c78e018ac4c/counties.rds"))
```

```{r}
# store the read data as a .csv file
# write.csv(mydata, file = "mydata.csv")
```

```{r , message=FALSE , warning=FALSE}
# load the data
mydata <- read_csv("mydata.csv")
```

## Explore Values ; glimpse()

If you want to see a few values from all the columns, you can use glimpse()

```{r}
glimpse(mydata)
```

The dataset has 3138 observations (rows) across 40 variables(columns)

## Selecting Columns : select()

Datasets often come with more variables than you need.. We will collect only a few variables: the state, the county, the total population, and the unemployment rate. We can do this using the select() verb. ***select()*** extracts only particular variables from a dataset. In this case, you can type counties, then the pipe operator, then select, then the variables of interest.

```{r}
mydata %>% # call the data set
    select(state, county, population, unemployment) # select desired columns
```

Sometimes you want to keep the data you've selected. You can use assignment to create a new table. Recall that you use the arrow operator, written as "less than dash", for this

```{r}
# creating a new table from existing table
counties_selected <- mydata %>%
    select(state, county, population, unemployment)

# glimpse the new table
glimpse(counties_selected)
```

Let us select only the state ; county ; population and poverty

```{r}
mydata %>%
    select(state , county , population , poverty)
```

## Arranging Rows : arrange()

Sometimes all the data you want is in your data frame, but it's all unorganized! The dplyr function arrange() will sort the rows of a data frame in ascending order by the column provided as an argument.

-   ***For numeric columns, ascending order means from lower to higher numbers.***

-   ***For character columns, ascending order means alphabetical order from A to Z.***

***Syntax : dataframe %\>% arrange(variable(s)\_to_sort)***

***Note : By default the arrange() function arranges data by ascending order***

Let us arrange our "counties_selected" table by population

```{r}
# arrange ascending order of population
counties_selected %>%
    arrange(population)
```

There is one county in Hawaii which has a population of 85 people

Let us examine which county has the highest population.To do this we ass the desc() argument

```{r}
# arrange descending order of population
counties_selected %>% 
    arrange(desc(population))
```

The highest population is Los Angeles, California, which is one of the biggest cities in the United States

## Filtering Rows : filter()

### Filter by Condition

The filter() function can subset rows of a data frame based on logical operations of certain columns. The condition of the filter should be explicitly passed as a parameter

***Syntax: name of the column, operator(\<,==,\>,!=) and value.***

You can add a pipe operator, then add another verb. You can pipe any number of verbs together to transform your dataset.For example, after the arrange(), you could add filter state equals equals quote New York to get only counties in the state of New York

```{r}
# arrange descending order of population
counties_selected %>% 
    arrange(desc(population)) %>% 
    # filer only those rows where state is New York
    filter(state == "New York")
```

Notice that the observations are filtered, but they're still sorted by population thanks to our arrange()

Besides "==", you can filter based on logical operators like less than or greater than. For example, you could filter for counties that have an unemployment rate of less than 6 percent. The condition in the filter would be unemployment less than 6.

```{r}
# arrange descending order of population
counties_selected %>% 
    arrange(desc(population)) %>%
    # filter only those rows where unemployment is < 6
    filter(unemployment < 6)
```

The largest counties with an unemployment rate below 6 percent are Fairfax, Virginia and Salt Late, Utah

The filter() function also allows for more complex filtering with the help of logical operators!

We filtered for the state of New York and for unemployment below 6 percent. We can do both at the same time if we separate them with a comma

```{r}
# arrange descending order of population
counties_selected %>% 
    arrange(desc(population)) %>% 
    # filter for New York and unployment < 6
    filter(state == "New York" , 
           unemployment < 6)
```

It looks like only a few counties in New York have an unemployment rate that is \< 6%.

Let us see the counties_selected dataset with a few interesting variables selected. These variables: private_work, public_work, self_employed describe whether people work for the government, for private companies, or for themselves.

```{r}
# selecting key columns
counties_selected_2 <- mydata %>%
  select(state, county, population, private_work, public_work, self_employed)

counties_selected_2 %>%
  # Add a verb to sort in descending order of public_work
  arrange(desc(public_work))
```

This looks odd.. 64% of the population of Kalawao county are employed in public office.

Let us look at observations in counties that have a large population (\< 1M)

Let us look at only state,Â county and population and then filter rows with population \> 1M

```{r}
# create anew table with desired columns only
counties_selected_3 <- mydata %>%
    select(state , county , population) 

glimpse(counties_selected_3)
```

```{r}
# filter counties with pupulation > 1M
counties_selected_3 %>%
    filter(population > 1000000)
```

Let us find only the counties in the state of California that also have a population above one million

```{r}
counties_selected_3 %>%
    filter(population > 1000000 , 
           state == "California")
```

There are 9 counties in the state of California with a population greater than one million

### Filtering and Arranging

We're often interested in both filtering and sorting a dataset, to focus on observations of particular interest.

Let us filter for counties in the state of Texas that have more than ten thousand people (10000), and sort them in descending order of the percentage of people employed in private work.

```{r}
# Filter for Texas and more than 10000 people; sort in descending order of private_work
counties_selected_2 %>%
  # Filter for Texas and more than 10000 people
  filter(state == "Texas" , 
         population > 10000) %>%
  # Sort in descending order of private_work
  arrange(desc(private_work))
```

We find that there are extreme examples of what fraction of the population works in the private sector

## Adding a Column : mutate()

When working with data frames, we often need to modify the columns for our analysis at hand.Th new column(s) could be a calculation based on the data that you already have. You can add a new column to the data frame using the mutate function.mutate() takes a name-value pair as an argument. The name will be the name of the new column you are adding, and the value is an expression defining the values of the new column in terms of the existing columns. mutate() returns a new data frame with the added column.

***Note : It is a best practice to give the added column a name.***

What if we are interested in the total number of unemployed people in a county, rather than as a percentage of the population? We could use the formula population times unemployment divided by 100.We can also name this new column as unemployed_population

```{r}
# unemployed population
counties_selected %>%
    mutate(unemployed_population = population * unemployment / 100)
```

We can combine this new variable with other verbs to ask more questions of your data. For example, what counties have the highest number of unemployed people? We add arrange desc unemployed-underscore-population to our mutate.

```{r}
# unemployed population
counties_selected %>%
    # create a new column of unemployed population
    mutate(unemployed_population = population * unemployment / 100) %>%
    # arrange by descending order of unemployed population
    arrange(desc(unemployed_population)) %>%
    # look at top 6 
    head()
```

Los Angeles has the highest unemployed population close to 1M which is 10% of the total population of LA

Let us shift our focus to "Government Employees". Let us first calculate the number of public workers. Notice that % of public workers is recorded in the public_work column. We will use this to derive the total number of public workers

```{r}
# create the data frame of selected columns only
counties_selected_4 <- mydata %>%
  select(state, county, population, public_work)

glimpse(counties_selected_4)
```

Create the new column with number of public workers and then sort in descending order

```{r}
# Create a new column for # of public workers
counties_selected_4 %>%
  # Add public_workers with the number of people employed in public work
  mutate(public_workers = public_work * population / 100) %>%
  # Arrange in descending order
  arrange(desc(public_workers)) %>%
  # Top 6 Rows
  head()
```

It looks like Los Angeles is the county with the most government employees

Let us look at Gender Diversity i.e. how many women employees do we have.The dataset includes columns for the total number (not percentage) of men and women in each county. We could use this, along with the `population` variable, to compute the fraction of men (or women) within each county.

```{r}
# Select only the desired columns we want
mydata %>% 
    # Select the columns state, county, population, men, and women
  select(state, county, population, men , women) %>%
    # Calculate proportion_women as the fraction of the total population
  mutate(proportion_women = women / population)
```

Notice that the proportion_women variable was added as a column to the dataset, and the data now has 6 columns instead of 5

## Select+Mutate + Filter + Arrange

Putting it all together

In this exercise, we will put together everything we have learned so far (select(), mutate(), filter() and arrange()), to find the counties with the highest proportion of men.

-   Select only the columns state, county, population, men, and women.

-   Add a variable proportion_men with the fraction of the county's population made up of men.

-   Filter for counties with a population of at least ten thousand (10000).

-   Arrange counties in descending order of their proportion of men.

```{r}
mydata %>%
    # Select the five columns
    select(state , county , population , men , women) %>%
    # Add the proportion_men variable
    mutate(proportion_men = men / population) %>%
    # Filter for population of at least 10,000
    filter(population >= 10000) %>%
    # Arrange proportion of men in descending order
    arrange(desc(proportion_men)) %>%
    # View Top 6 Rows
    head()

```

Notice Sussex County in Virginia is more than two thirds male: this is because of two men's prisons in the county

# Aggregating Data

Now that we know how to transform your data, we want to know more about how to aggregate your data to make it more interpretable. There are a number of functions use can use to take many observations in a dataset and summarize them, Common data aggregation include count , minimum , maximum , mean, median, and standard deviation to name a few.

## Count : count()

### Simple Count

The simplest way we can aggregate data is to count it: to find out the number of observations. The dplyr verb for this is count() , which results is a one-row table, with one column called.

```{r}
# simple count of observations in the data
mydata %>%
    count()
```

This tells us there are 3,138 observations in the table. Counting the total data is a little useful, but the real value of the verb is when you give it a specific variable to count. For example, we could count the number of counties in each state.

```{r}
# how many counties 
mydata %>%
    count(state)
```

Notice that the result has 50 observations: one for each of the 50 states. We've aggregated more than three thousand observations into a more manageable number. The second column, n, tells us there are 67 counties in Alabama, 28 in Alaska, and so on

### Count and Sort

The count verb takes a second argument sort that's very useful for that. resulting in rows sorted from the most common observations to the least.Note that we need to specif "sort = TRUE"

```{r}
# counting the number of counties by state and sorting
mydata %>%
    count(state , sort = TRUE)
```

This tells us that Texas is the state with the most counties, followed by Georgia and Virginia

### Count + Weight + Sort

Let us aggregate the total population of each county

We can add the argument wt, which stands for "weight", equals population. This means that the n column will be weighted by the population. In the result, instead of seeing the number of counties in each state, we'd see the total population

```{r}
# population of each county
mydata %>%
    count(state , wt = population , sort = TRUE)
```

Here we can see that California is the US state with the highest population, followed by Texas and New York

The counties dataset contains columns for region, state, population, and the number of citizens, which we selected and saved as the counties_selected.Let us create a separate table with county , region , state , population and citizens

```{r}
# create a new table with desired columns
counties_selected <- mydata %>%
    select(county , region , state , population , citizens)

counties_selected %>%
    head()
```

1.  **How many counties within each region?**

```{r}
counties_selected %>%
    count(region , sort = TRUE)
```

Since the results have been arranged, you can see that the South has the greatest number of counties

2.  **How many counties in each state, weighted based on the citizens**

```{r}
counties_selected %>%
    count(state , wt = citizens , sort = TRUE)
```

From our result, we can see that California is the state with the most citizens

### Count + Mutate

We can combine multiple verbs together to answer increasingly complicated questions of our data.

3.  **What are the US states where the most people walk to work?**

Let us use the walk column, which offers a **percentage of people** in each county that walk to work, to add a new column and count based on it.

```{r}
# update the table to include walk
counties_selected <- mydata %>%
    select(county, region, state, population,citizens , walk )

counties_selected %>% head()
```

Let us use the mutate statement to calculate and add a column called population_walk, containing the total number of people who walk to work in a county.Note the walk column gives % of population who walk.

population who walk = (population \*(% walk) /100

```{r , options(scipen = 1, digits = 3)}
counties_selected %>%
    # create a column population who walk
    mutate(population_walk = population * walk/100)
```

Let us now use the weight method to count the total number of people who walk in each state

```{r}
counties_selected %>%
    # create a column population who walk
    mutate(population_walk = population * walk/100) %>%
    # count each state weighted by population
    count(state, wt = population_walk, sort = TRUE)
```

Though California had the largest total population, New York state has the largest number of people who walk to work.

### Grouping + Summarizing : group_by() ; summarize()

#### Summarize() : Summary

The summarize verb takes many observations and turns them into one observation.To *combine* all of the values from a column for a single calculation , we take the help of the dplyr function summarize(), which returns a new data frame containing the desired calculation.

The general syntax for summarizing calculations is:

    df %>%
    summarize(var_name = command(column_name))

-   df is the data frame you are working with

-   summarize is a dplyr function that reduces multiple values to a single value

-   var_name is the name you assign to the column that stores the results of the summary function in the returned data frame

-   command is the summary function that is applied to the column by summarize()

-   column_name is the name of the column of df that is being summarized

The following table includes common summary functions that can be given as an argument to summarize():

+---------------------+------------------------------------------------+
| Command             | Description                                    |
+=====================+================================================+
| mean()              | Average of all values in column                |
+---------------------+------------------------------------------------+
| median()            | Median value of column                         |
+---------------------+------------------------------------------------+
| sd()                | Standard deviation of column                   |
+---------------------+------------------------------------------------+
| var()               | Variance of column                             |
+---------------------+------------------------------------------------+
| min()               | Minimum value in column                        |
+---------------------+------------------------------------------------+
| max()               | Maximum value in column                        |
+---------------------+------------------------------------------------+
| IQR()               | Interquartile range of column                  |
+---------------------+------------------------------------------------+
| n_distinct()        | Number of unique values in column              |
+---------------------+------------------------------------------------+
| sum()               | Sum values of column                           |
+---------------------+------------------------------------------------+

Let us find the total population of the United States

```{r}
mydata %>%
    summarize(total_population = sum(population))
```

We can define multiple variables in a summarize, and you can aggregate each in different ways. For example, you could find the total population, but also the average unemployment rate

```{r}
mydata %>%
    summarize(total_population = sum(population) , 
              average_unemployment = mean(unemployment))
```

#### Group_By() : Aggregates

When we have a bunch of data, we often want to calculate aggregate statistics (mean, standard deviation, median, percentiles, etc.) over certain subsets of the data.We accomplish this by applying the group_by() verb followed by the summarize verb.This is called "Aggregation".

General syntax to calculate aggregates:

    df %>%
    group_by(column_1) %>%
    summarize(aggregate_name =command(column_2))

-   column_1 (student in our example) is the column that we want to group_by()

-   column_2 (grade in our example) is the column that we want to apply command(), a summary function, to using summarize()

-   aggregate_name is the name assigned to the calculated aggregate

Let us find the total population within each state and the average unemployment

```{r}
mydata %>%
    group_by(state) %>% # grouping column
    summarize(state_pop   = sum(population) ,  # summary stat 1
              state_unemp = mean(unemployment)) %>% # summary stat 2
    ungroup() # ungroup
```

Let us clean this further by arranging in descending order to find states with highest unemployment

```{r}
mydata %>%
    group_by(state) %>%
    summarize(state_pop  = sum(population) , 
              mean_unemp = mean(unemployment)) %>%
    ungroup() %>%
    arrange(desc(mean_unemp))
```

Mississippi is the state with the highest unemployment

Sometimes, we want to group by more than one column. We can do this by passing multiple column names as arguments to the group_by function.

The dataset also includes a metro column, which describes whether the county is a metro area- that is, a city or non-metro

Let us view the population by state and by metro

```{r}
mydata %>%
    select(state, metro, county, population) %>%
    group_by(state , metro) %>%
    summarize(tot_pop = sum(population)) %>%
    ungroup()
```

Instead of 50 observations in the output, we have 97, since a few states don't have any counties that aren't metro areas. For instance, here we see that the total population in Alabama metro areas is 3-point-6 million, and the population in non-metro areas is 1.2M.

-   Summarize the counties dataset to find the following columns: min_population (with the smallest population), max_unemployment (with the maximum unemployment), and average_income (with the mean of the income variable).Select only county, population, income, unemployment)

```{r}
mydata %>%
    select(county , population , income , unemployment)%>%
    summarize(min_population    = min(population) , 
              max_unemployment  = max(unemployment) , 
              average_income = mean(income))
```

Another interesting column is land_area, which shows the land area in square miles. Here, you'll summarize both population and land area by state, with the purpose of finding the density (in people per square miles).

-   Group the data by state, and summarize to create the columns total_area (with total area in square miles) and total_population (with total population).Select only state, county, population, land_area

-   Next add a density column with the people per square mile, then arrange in descending order

```{r}
mydata %>%
    select(state, county, population, land_area) %>% # select desired columns
    group_by(state) %>% # group by state
    summarize(total_area       = sum(land_area) , # stat 1
              total_population = sum(population) , # stat 2 
              density          = total_population / total_area) %>%
    ungroup() %>%
    arrange(desc(density)) # arrange descending order
```

New Jersey and Rhode Island are the "most crowded" of the US states, with more than a thousand people per square mile

-   Summarize to find the total population, as a column called total_pop, in each combination of region and state.

-   Calculate two new columns: the average state population in each region (average_pop) and the median state population in each region (median_pop)

```{r}
mydata %>%
    # Group and summarize to find the total population
  group_by(region, state) %>%
  summarize(total_pop = sum(population)) %>%
  # Calculate the average_pop and median_pop columns 
  summarize(average_pop = mean(total_pop),
            median_pop = median(total_pop)) %>%
    ungroup()
```

The South Region has the highest average_pop of 7.3M, while North Central region has the highest median_pop of .5M.

### Top(top_n) : Ranking

Let's say , instead of aggregating , we want to find only the largest or smallest value in a group. dplyr's top_n is very useful for keeping the most extreme observations from each group

Like summarize(), top_n operates on a grouped table. The function takes two arguments: the number of observations you want from each group, and the column you want to weight by.

**General Syntax : top_n(x, n, wt)**

x : A data frame.

n : \# of rows to return for top_n(). If n is positive, selects the top rows. If negative, selects the bottom rows. If x is grouped, this is the number of rows per group.

wt : (Optional). The variable to use for ordering. If not specified, defaults to the last variable in the tbl.

Let us find out the county with highest population in each state. Select only state, county, population, unemployment, income

```{r}
mydata %>%
    # select the desired columns
    select(state, county, population, unemployment, income) %>%
    # group by state
    group_by(state) %>%
    # get the "Top County" with highest population 
    top_n(1 , population)
```

This tells us, for example, that Jefferson is the highest population county in Alabama with a population of 659K.

Let us find out which are the Top 3 counties within each state with highest unemployment

```{r}
mydata %>%
    select(state, county, population, unemployment, income) %>%
    group_by(state) %>%
    top_n(3 , unemployment)
```

For Alabama these turn out to be named Conecuh, Monroe, and Wilcox.

**Top n is often used when creating graphs, where we're interested in pulling the extreme examples to include in the visualization**

-   Find the county in each region with the highest percentage of citizens who walk to work

-   Select only region, state, county, metro, population, walk

```{r}
mydata %>%
    # select the desired columns
    select(region, state, county, metro, population, walk) %>%
    # group by region
    group_by(region) %>%
    # top county by % citizens who walk
    top_n(1 , walk)
    
```

Notice that three of the places lots of people walk to work are low-population non-metro counties, New York City also pops up

-   **Finding the highest-income state in each region.**

We will combine group_by(), summarize(), and top_n() to find the state in each region with the highest income.

When you group by multiple columns and then summarize, it's important to remember that the summarize "peels off" one of the groups, but leaves the rest on. For example, if you `group_by(X, Y)` then summarize, the result will still be grouped by `X`.

Select only region, state, county, population, income

```{r}
mydata %>%
    # select the desired columns
    select(region, state, county, population, income) %>%
    # group by region and state
    group_by(region , state) %>%
    # calculate the average income
    summarize(average_income = mean(income)) %>%
    # find the highest income state in each region
    top_n(1 , average_income) %>%
    ungroup()
```

From our results, we can see that the New Jersey in the Northeast is the state with the highest average_income of 73014.

# Selecting and Transforming Data 

This section focuses on advanced methods of selecting and transforming columns. We will cover select helpers, which are functions that specify criteria for columns you want to choose, as well as the rename and transmute verbs

## Select Range of Columns

We have seen that we can select the columns that we're interested in, using the select verb. We can also select a range of columns.Our dataset has a set of columns about the breakdown of jobs across industries, and we want all of the columns from professional to production.

**General Syntax : df %\>% select(col1:col2)**

df : data frame from which columns are needed

col1 : starting column name

col2 : ending column name

```{r}
# column names of dataset
names(mydata)
```

```{r}
mydata %>%
    # select range of columns using ":" notation
    select(state , county , professional:production) %>%
    head()
```

If we wanted to know just the columns about how people get to work, you could do drive : work_at_home

```{r}
mydata %>%
    select(state , county , drive : work_at_home) %>%
    head()
```

Let us arrange these columns by "drive" which is driving distance

```{r}
mydata %>%
    select(state , county , drive : work_at_home) %>%
    arrange(drive)%>%
    head()
```

Interesting insights : Alaska -- Drive to Work maximum while New York -- Transit to Work (Sub-way)

## Select Helpers :

Select has other ways to get only the columns you want using "select helpers": functions that specify criteria for choosing columns

***The following functions helps you to select variables based on their names***

+---------------+-------------------------------------+
| Helpers       | Description                         |
+===============+=====================================+
| starts_with() | Starts with a prefix                |
+---------------+-------------------------------------+
| ends_with()   | Ends with a prefix                  |
+---------------+-------------------------------------+
| contains()    | Contains a literal string           |
+---------------+-------------------------------------+
| matches()     | Matches a regular expression        |
+---------------+-------------------------------------+
| num_range()   | Numerical range like x01, x02, x03. |
+---------------+-------------------------------------+
| one_of()      | Variables in character vector.      |
+---------------+-------------------------------------+
| everything()  | All variables.                      |
+---------------+-------------------------------------+

Let us select all the columns that contain"work"

```{r}
mydata %>%
    select(state , county , contains("work")) %>%
    head()
```

Notice that we put work into quotes, unlike state and county. Select helpers take **strings,** which means they're in quotes. The result has all the columns that contain the word "work".

Let us get all the columns that begin with the word "income", which are generally related to each other

```{r}
mydata %>%
    select(state , county , starts_with("income")) %>%
    head()
```

## De-Selecting / Removing Columns

We can use select to remove variables from a table by adding a "minus" in front of the column name

Let us exclude the column census_id

```{r}
mydata %>%
    select(-census_id) %>%
    names()
```
